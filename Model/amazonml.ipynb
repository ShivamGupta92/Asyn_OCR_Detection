{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2CEhcYrAy08"
      },
      "outputs": [],
      "source": [
        "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "from pprint import pprint\n",
        "import bitsandbytes as bnb\n",
        "import torch\n",
        "import wandb\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "from datasets import load_dataset, Dataset\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "\n",
        "from peft import LoraConfig, PeftConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
        "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig"
      ],
      "metadata": {
        "id": "NOdwaZfnBcJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
      ],
      "metadata": {
        "id": "zfmPuEaTByNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"NousResearch/Llama-2-7b-chat-hf\"\n",
        "MODEL_NAME = model\n"
      ],
      "metadata": {
        "id": "71lKDtcZCEjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    quantization_config=bnb_config\n",
        ")\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)\n"
      ],
      "metadata": {
        "id": "chr6ITqhCI4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def get_num_layers(model):\n",
        "    numbers = set()\n",
        "    for name, _ in model.named_parameters():\n",
        "        for number in re.findall(r'\\d+', name):\n",
        "            numbers.add(int(number))\n",
        "    return max(numbers)\n",
        "\n",
        "\n",
        "def get_last_layer_linears(model):\n",
        "    names = []\n",
        "\n",
        "    num_layers = get_num_layers(model)\n",
        "    for name, module in model.named_modules():\n",
        "        if str(num_layers) in name and not \"encoder\" in name:\n",
        "            if isinstance(module, torch.nn.Linear):\n",
        "                names.append(name)\n",
        "    return names\n"
      ],
      "metadata": {
        "id": "RdvhRKkgCLy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = LoraConfig(\n",
        "    r=2,\n",
        "    lora_alpha=32,\n",
        "    target_modules=get_last_layer_linears(model),\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "\n",
        "model = get_peft_model(model, config)\n"
      ],
      "metadata": {
        "id": "duskFBRoC4yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/tester2.csv\")\n",
        "df.columns = [str(q).strip() for q in df.columns]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lgtEu-IdC7di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "\n",
        "# Entity unit map provided in the input\n",
        "entity_unit_map = {\n",
        "    \"width\": {\"centimetre\", \"foot\", \"millimetre\", \"metre\", \"inch\", \"yard\"},\n",
        "    \"depth\": {\"centimetre\", \"foot\", \"millimetre\", \"metre\", \"inch\", \"yard\"},\n",
        "    \"height\": {\"centimetre\", \"foot\", \"millimetre\", \"metre\", \"inch\", \"yard\"},\n",
        "    \"item_weight\": {\"milligram\", \"kilogram\", \"microgram\", \"gram\", \"ounce\", \"ton\", \"pound\"},\n",
        "    \"maximum_weight_recommendation\": {\"milligram\", \"kilogram\", \"microgram\", \"gram\", \"ounce\", \"ton\", \"pound\"},\n",
        "    \"voltage\": {\"millivolt\", \"kilovolt\", \"volt\"},\n",
        "    \"wattage\": {\"kilowatt\", \"watt\"},\n",
        "    \"item_volume\": {\"cubic foot\", \"microlitre\", \"cup\", \"fluid ounce\", \"centilitre\", \"imperial gallon\", \"pint\", \"decilitre\", \"litre\", \"millilitre\", \"quart\", \"cubic inch\", \"gallon\"}\n",
        "}\n",
        "\n",
        "# Function to extract valid entity value\n",
        "def extract_entity_value(ocr_text, entity_name):\n",
        "    # Join OCR text into a single string\n",
        "    ocr_text_str = ' '.join(ocr_text)\n",
        "\n",
        "    # Get the allowed units for the entity_name\n",
        "    allowed_units = entity_unit_map.get(entity_name, [])\n",
        "\n",
        "    # Regular expression to capture valid entity values with allowed units\n",
        "    pattern = r\"(\\d+\\.?\\d*)\\s?(\" + \"|\".join(allowed_units) + r\")\\b\"\n",
        "\n",
        "    # Search for matching patterns in the OCR text\n",
        "    matches = re.findall(pattern, ocr_text_str)\n",
        "\n",
        "    # Return formatted entity value if found, else an empty string\n",
        "    if matches:\n",
        "        # Concatenate the first valid match found\n",
        "        return f\"{matches[0][0]} {matches[0][1]}\"\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create a new column for cleaned OCR text\n",
        "df['clean_ocr_text'] = df['ocr_text'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Apply the extraction function to get the entity value\n",
        "df['entity_value_extracted'] = df.apply(lambda row: extract_entity_value(row['ocr_text'], row['entity_name']), axis=1)\n",
        "\n",
        "# Generate the output prompt format\n",
        "df['question'] = df.apply(lambda row: f\"For {row['group_id']} please find the {row['entity_name']} in this text {row['clean_ocr_text'].strip()}.\", axis=1)\n",
        "\n",
        "# Show the final DataFrame\n"
      ],
      "metadata": {
        "id": "hTWMK05ZL7qV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = df[\"question\"].values[0]"
      ],
      "metadata": {
        "id": "n5dGxTZND7bD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = model.generation_config\n",
        "generation_config.max_new_tokens = 30\n",
        "generation_config.temperature = 0.3\n",
        "generation_config.top_p = 0.7\n",
        "generation_config.num_return_sequences = 1\n",
        "generation_config.pad_token_id = tokenizer.eos_token_id\n",
        "generation_config.eos_token_id = tokenizer.eos_token_id\n"
      ],
      "metadata": {
        "id": "5vIjaVvEEQP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(prompt):\n",
        "    device = \"cuda\"\n",
        "    encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids = encoding.input_ids,\n",
        "            attention_mask = encoding.attention_mask,\n",
        "            generation_config = generation_config\n",
        "        )\n",
        "    full_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    answer = full_output.split(prompt)[-1]  # Assumes the answer follows the prompt\n",
        "    return answer.strip()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "izO_uA_PEStj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    f\"For group_id {row['group_id']}, find {row['entity_name']} in {row['ocr_text'].strip()}. Give the entity name in this format :  the entity value is = <entity_value>\"\n",
        "    for _, row in df.iterrows()\n",
        "]"
      ],
      "metadata": {
        "id": "HCyGDH3UOVDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_answers = [generate_answer(question.strip()) for question in questions]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oCj3HnmDEaRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Sample text data\n",
        "text_data = testing_answers\n",
        "\n",
        "# Regular expressions to capture group_id, entity_value, and corresponding value\n",
        "group_id_pattern = r\"group_id\\s*=\\s*(\\d+)\"\n",
        "entity_value_pattern = r\"entity_value\\s*=\\s*([^\\n]+)\"\n",
        "value_pattern = r\"(width|depth|height|weight|voltage)\\s*is\\s*([\\d\\.]+[a-zA-Z]+)\"\n",
        "\n",
        "# Lists to store the extracted data\n",
        "group_ids = []\n",
        "entity_values = []\n",
        "values = []\n",
        "\n",
        "# Process each text block\n",
        "for text in text_data:\n",
        "    group_id_match = re.search(group_id_pattern, text)\n",
        "    entity_value_match = re.search(entity_value_pattern, text)\n",
        "    value_match = re.search(value_pattern, text)\n",
        "\n",
        "    # Extract group_id, entity_value, and corresponding value\n",
        "    if group_id_match and entity_value_match and value_match:\n",
        "        group_ids.append(group_id_match.group(1))\n",
        "        entity_values.append(entity_value_match.group(1))\n",
        "        values.append(value_match.group(2))\n",
        "    else:\n",
        "        # Handle missing information\n",
        "        group_ids.append(group_id_match.group(1) if group_id_match else \"N/A\")\n",
        "        entity_values.append(entity_value_match.group(1) if entity_value_match else \"N/A\")\n",
        "        values.append(value_match.group(2) if value_match else \"N/A\")\n",
        "\n",
        "# Create a pandas DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'group_id': group_ids,\n",
        "    'entity_value': entity_values,\n",
        "    'value': values\n",
        "})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "output_csv_path = 'extracted_entity_values.csv'\n",
        "df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(f\"Data successfully saved to {output_csv_path}\")\n"
      ],
      "metadata": {
        "id": "iefPR5KSFYLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/extracted_entity_values.csv')"
      ],
      "metadata": {
        "id": "H5OSmgDualzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dK97LZH3bqm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Djb4phobrlW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}