{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install aiohttp, paddlepaddle-gpu, paddleocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from paddleocr import PaddleOCR\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Event Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/09/16 11:07:34] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\shiva/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\shiva/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='c:\\\\Python311\\\\Lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='C:\\\\Users\\\\shiva/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    }
   ],
   "source": [
    "#Setup OCR model to run on GPU\n",
    "ocr_model = PaddleOCR(lang='en', use_gpu=True)\n",
    "# WIth CPU\n",
    "#ocr_model = PaddleOCR(lang='en', use_gpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronously fetch the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_image(image_url, session):\n",
    "    try:\n",
    "        async with session.get(image_url) as response:\n",
    "            if response.status == 200:  # Check for a valid response\n",
    "                img_array = np.asarray(bytearray(await response.read()), dtype=\"uint8\")\n",
    "                img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "                return img\n",
    "            else:\n",
    "                print(f\"Failed to fetch image: {image_url}, status: {response.status}\")\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching image from {image_url}: {e}\")\n",
    "        return None   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Resizing as fetched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run OCR on the fetched image and return extracted data\n",
    "def process_image(img):\n",
    "    try:\n",
    "        # Resize image for faster processing\n",
    "        img_resized = cv2.resize(img, (640, 640))  # Resizing image to 640x640\n",
    "        result = ocr_model.ocr(img_resized)\n",
    "        extracted_data = [result[0][i][1][0] for i in range(len(result[0]))]\n",
    "        return extracted_data\n",
    "    except Exception as e:\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asynchronous function to fetch images in parallel and run OCR\n",
    "async def process_images(data):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            loop = asyncio.get_event_loop()\n",
    "            tasks = []\n",
    "            for image_url in data['image_link']:\n",
    "                img = await fetch_image(image_url, session)\n",
    "                if img is not None:\n",
    "                    tasks.append(loop.run_in_executor(executor, process_image, img))\n",
    "                else:\n",
    "                    # If fetching image failed, return an empty list or default value\n",
    "                    tasks.append(loop.run_in_executor(executor, lambda: []))\n",
    "            ocr_results = await asyncio.gather(*tasks)\n",
    "            return ocr_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Batches and Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process in batches for large datasets\n",
    "def process_in_batches(data, batch_size=5000):\n",
    "    all_ocr_data = []\n",
    "    num_batches = len(data) // batch_size + 1\n",
    "\n",
    "    for batch_num in range(num_batches):\n",
    "        start = batch_num * batch_size\n",
    "        end = min((batch_num + 1) * batch_size, len(data))\n",
    "        batch_data = data.iloc[start:end]\n",
    "\n",
    "        # Apply async processing to fetch and process images in batches\n",
    "        ocr_results = asyncio.run(process_images(batch_data))\n",
    "\n",
    "        # Ensure the length of ocr_results matches batch_data\n",
    "        if len(ocr_results) < len(batch_data):\n",
    "            # If results are fewer, pad with None\n",
    "            ocr_results.extend([None] * (len(batch_data) - len(ocr_results)))\n",
    "        elif len(ocr_results) > len(batch_data):\n",
    "            # If more results (shouldn't happen), trim the list\n",
    "            ocr_results = ocr_results[:len(batch_data)]\n",
    "\n",
    "        # Save intermediate results to avoid data loss\n",
    "        batch_data['ocr_text'] = ocr_results\n",
    "        batch_data.to_csv(f\"dataset/testDta/test{batch_num}.csv\", index=False)\n",
    "\n",
    "    return pd.concat(all_ocr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and drop unnecessary columns\n",
    "# TEST Data\n",
    "data = pd.read_csv(\"dataset/sample_test.csv\", index_col=False)\n",
    "data = data.drop(['entity_name'], axis=1)\n",
    "\n",
    "\n",
    "# Load data and drop unnecessary columns\n",
    "# TRAIN Data\n",
    "# data = pd.read_csv(\"/content/Dataset/net_train.csv\", index_col=False)\n",
    "# data = data.drop(['entity_name', 'entity_value'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.sample(n=57000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset Index Must"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200</td>\n",
       "      <td>https://m.media-amazon.com/images/I/31porpKxyr...</td>\n",
       "      <td>478357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1201</td>\n",
       "      <td>https://m.media-amazon.com/images/I/31porpKxyr...</td>\n",
       "      <td>478357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1202</td>\n",
       "      <td>https://m.media-amazon.com/images/I/31pqPZnqje...</td>\n",
       "      <td>569206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1203</td>\n",
       "      <td>https://m.media-amazon.com/images/I/31pqoHDvL8...</td>\n",
       "      <td>442321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1204</td>\n",
       "      <td>https://m.media-amazon.com/images/I/31psy25ZB-...</td>\n",
       "      <td>276611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                         image_link  group_id\n",
       "0   1200  https://m.media-amazon.com/images/I/31porpKxyr...    478357\n",
       "1   1201  https://m.media-amazon.com/images/I/31porpKxyr...    478357\n",
       "2   1202  https://m.media-amazon.com/images/I/31pqPZnqje...    569206\n",
       "3   1203  https://m.media-amazon.com/images/I/31pqoHDvL8...    442321\n",
       "4   1204  https://m.media-amazon.com/images/I/31psy25ZB-...    276611"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust as per memory limits\n",
    "batch_size = 5000  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the threads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size and run processing\n",
    "process_in_batches(data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final result\n",
    "# processed_data.to_csv(\"dataset/TrainedOcr/train_with_ocr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 Combining Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Your list of URLs\n",
    "listUN = [f\"dataset/testDta/test{i}.csv\" for i in range(6)]\n",
    "\n",
    "# Read all CSV files into a list of DataFrames\n",
    "dfs = [pd.read_csv(url) for url in listUN]\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Optional: Save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv('test_ocr1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
